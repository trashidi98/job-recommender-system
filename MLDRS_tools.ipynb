{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zesha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zesha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zesha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import freeze_support\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.corpora as corpora\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from gensim.models import Phrases, CoherenceModel\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.test.utils import datapath\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.corpora import Dictionary\n",
    "import pickle\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "lemmatizer = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createList(corpus):\n",
    "    corpus_list = []\n",
    "    for i in range (len(corpus)):\n",
    "        temp = []\n",
    "        for word in (corpus[i]):\n",
    "            temp.append(word)\n",
    "        temp = \" \".join(temp)\n",
    "        corpus_list.append(temp)\n",
    "    return corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_clusters(dataframe1, max_k):\n",
    "    iters = range(1, max_k+1, 1)\n",
    "    \n",
    "    sse = []\n",
    "    for k in iters:\n",
    "        sse.append(MiniBatchKMeans(n_clusters=k, init_size=1024, batch_size=2048, random_state=100).fit(dataframe1).inertia_)\n",
    "        print('Fit {} clusters'.format(k))\n",
    "        \n",
    "    f, ax = plt.subplots(1, 1)\n",
    "    ax.plot(iters, sse, marker='o')\n",
    "    ax.set_xlabel('Cluster Centers')\n",
    "    ax.set_xticks(iters)\n",
    "    ax.set_xticklabels(iters)\n",
    "    ax.set_ylabel('SSE')\n",
    "    ax.set_title('SSE by Cluster Center Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_pca(dataframe1, labels):\n",
    "    max_label = max(labels)\n",
    "    max_items = np.random.choice(range(dataframe1.shape[0]), size=10000, replace=False)\n",
    "    \n",
    "    pca = PCA(n_components=2).fit_transform(dataframe1[max_items,:].todense())\n",
    "    tsne = TSNE().fit_transform(PCA(n_components=50).fit_transform(dataframe1[max_items,:].todense()))    \n",
    "    \n",
    "    idx = np.random.choice(range(pca.shape[0]), size=300, replace=False)\n",
    "    label_subset = labels[max_items]\n",
    "    label_subset = [cm.hsv(i/max_label) for i in label_subset[idx]]\n",
    "    \n",
    "    f, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    ax[0].scatter(pca[idx, 0], pca[idx, 1], c=label_subset)\n",
    "    ax[0].set_title('PCA Cluster Plot')\n",
    "    \n",
    "    ax[1].scatter(tsne[idx, 0], tsne[idx, 1], c=label_subset)\n",
    "    ax[1].set_title('TSNE Cluster Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(resume_topics, job_topics):\n",
    "    \n",
    "    weights = [0.25, 0.18, 0.15, 0.13, 0.11, 0.09, 0.05, 0.04]\n",
    "    distribution = [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3]\n",
    "    \n",
    "    accuracy_lst = []\n",
    "    for topic in resume_topics:\n",
    "        if topic not in job_topics:\n",
    "            accuracy_lst.append(0)\n",
    "        else:\n",
    "            current_weight = weights[resume_topics.index(topic)]\n",
    "            job_index = job_topics.index(topic)\n",
    "            resume_index = resume_topics.index(topic)\n",
    "            temp = abs(job_index - resume_index)\n",
    "            distrib_num = distribution[temp]\n",
    "            accuracy_lst.append(distrib_num*current_weight)\n",
    "\n",
    "    return (((round((sum(accuracy_lst)),2)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
